{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ba8194",
   "metadata": {},
   "source": [
    "# üìò Rick and Morty Sentiment & Topic Analysis Notebook\n",
    "This notebook contains:\n",
    "- Part 1: Sentiment Analysis (VADER & TextBlob)\n",
    "- Part 2: Topic Modeling with NMF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35e9ba",
   "metadata": {},
   "source": [
    "## üü¶ Part 1: Sentiment Analysis (VADER & TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6719cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from docx import Document\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Load Data\n",
    "df = pd.read_csv(\"Rick-n-Morty[1].csv\")\n",
    "df['dialogue'] = df['dialogue'].astype(str)\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.rename(columns={'Season No': 'season', 'Episode': 'episode', 'IMDb score': 'imdb_score'})\n",
    "\n",
    "# Load Comments\n",
    "def read_docx(path):\n",
    "    doc = Document(path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "high_comments = read_docx(\"Highest rated Episode Comments.docx\")\n",
    "low_comments = read_docx(\"Least rated Episode Comments.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48aadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üòä TextBlob Analysis on Comments\n",
    "high_blob = TextBlob(high_comments)\n",
    "low_blob = TextBlob(low_comments)\n",
    "\n",
    "high_polarity = high_blob.sentiment.polarity\n",
    "high_subjectivity = high_blob.sentiment.subjectivity\n",
    "low_polarity = low_blob.sentiment.polarity\n",
    "low_subjectivity = low_blob.sentiment.subjectivity\n",
    "\n",
    "print(\"High-Rated Comments - Polarity:\", high_polarity)\n",
    "print(\"High-Rated Comments - Subjectivity:\", high_subjectivity)\n",
    "print(\"Low-Rated Comments - Polarity:\", low_polarity)\n",
    "print(\"Low-Rated Comments - Subjectivity:\", low_subjectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí¨ VADER Analysis on Dialogues\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['vader'] = df['dialogue'].apply(analyzer.polarity_scores)\n",
    "df['compound'] = df['vader'].apply(lambda x: x['compound'])\n",
    "df['pos'] = df['vader'].apply(lambda x: x['pos'])\n",
    "df['neu'] = df['vader'].apply(lambda x: x['neu'])\n",
    "df['neg'] = df['vader'].apply(lambda x: x['neg'])\n",
    "\n",
    "# Also apply TextBlob on script lines\n",
    "df['polarity'] = df['dialogue'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['subjectivity'] = df['dialogue'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "df['imdb_score'] = pd.to_numeric(df['imdb_score'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384724f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Aggregated Sentiment Per Episode and Character\n",
    "episode_sentiment = df.groupby(['season', 'episode']).agg({\n",
    "    'compound': 'mean',\n",
    "    'pos': 'mean',\n",
    "    'neu': 'mean',\n",
    "    'neg': 'mean',\n",
    "    'polarity': 'mean',\n",
    "    'subjectivity': 'mean',\n",
    "    'imdb_score': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "top_characters = df['speaker'].value_counts().head(6).index.tolist()\n",
    "character_sentiment = df[df['speaker'].isin(top_characters)].groupby(['speaker', 'season', 'episode']).agg({\n",
    "    'polarity': 'mean',\n",
    "    'imdb_score': 'first'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce1242",
   "metadata": {},
   "source": [
    "### üìä Visualizations for Part 1\n",
    "This includes:\n",
    "- Polarity vs IMDb Rating\n",
    "- Subjectivity vs IMDb Rating\n",
    "- Character-wise Polarity vs IMDb\n",
    "- Correlation Heatmap\n",
    "- Season/Episode Sentiment Trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà 1. Polarity vs IMDb Rating\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.regplot(data=episode_sentiment, x='polarity', y='imdb_score', color='orange')\n",
    "plt.title('Polarity vs IMDb Rating')\n",
    "plt.xlabel('Average Polarity')\n",
    "plt.ylabel('IMDb Rating')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà 2. Subjectivity vs IMDb Rating\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.regplot(data=episode_sentiment, x='subjectivity', y='imdb_score', color='orange')\n",
    "plt.title('Subjectivity vs IMDb Rating')\n",
    "plt.xlabel('Average Subjectivity')\n",
    "plt.ylabel('IMDb Rating')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà 3. Character-wise Polarity vs IMDb Rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(\n",
    "    data=character_sentiment,\n",
    "    x='polarity',\n",
    "    y='imdb_score',\n",
    "    hue='speaker',\n",
    "    height=6,\n",
    "    aspect=1.5,\n",
    "    scatter_kws={'alpha': 0.6}\n",
    ")\n",
    "plt.title(\"Character-wise Sentiment vs IMDb Rating\", y=1.03)\n",
    "plt.xlabel(\"Character Average Polarity\")\n",
    "plt.ylabel(\"IMDb Rating\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà 4. Correlation Heatmap (VADER + IMDb)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    episode_sentiment[['compound', 'pos', 'neg', 'neu', 'imdb_score']].corr(),\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.2f'\n",
    ")\n",
    "plt.title(\"Sentiment vs IMDb Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà 5. Season-level Line Plot\n",
    "season_summary = episode_sentiment.groupby('season').mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=season_summary, x='season', y='compound', label='Compound')\n",
    "sns.lineplot(data=season_summary, x='season', y='imdb_score', label='IMDb Score')\n",
    "plt.title('Average Compound Sentiment and IMDb Score per Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà 6. Episode-wise Sentiment Trend\n",
    "episode_sorted = episode_sentiment.sort_values(by=['season', 'episode']).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "sns.lineplot(x=episode_sorted.index, y=episode_sorted['compound'], label='Compound Sentiment')\n",
    "sns.lineplot(x=episode_sorted.index, y=episode_sorted['imdb_score'], label='IMDb Score')\n",
    "plt.title('Sentiment and IMDb Score Over Episodes')\n",
    "plt.xlabel('Episode Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc9063",
   "metadata": {},
   "source": [
    "## üü® Part 2: Topic Modeling with TF-IDF + NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d76fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üì¶ TF-IDF + NMF Preparation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import re\n",
    "\n",
    "# Combine all dialogues per episode\n",
    "episode_texts = df.groupby(['season', 'episode'])['dialogue'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "episode_texts['clean_text'] = episode_texts['dialogue'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üß† TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "dtm = tfidf.fit_transform(episode_texts['clean_text'])\n",
    "\n",
    "# üîç NMF Topic Modeling\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "topic_matrix = nmf.fit_transform(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üí° Add Topic Weights to DataFrame\n",
    "topic_df = pd.DataFrame(topic_matrix, columns=[f'Topic_{i+1}' for i in range(5)])\n",
    "topics = pd.concat([episode_texts[['season', 'episode']], topic_df], axis=1)\n",
    "\n",
    "# üîó Merge with IMDb\n",
    "topics = pd.merge(topics, episode_sentiment[['season', 'episode', 'imdb_score']], on=['season', 'episode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üè∑Ô∏è Extract Top Keywords for Each Topic\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "topic_keywords = {}\n",
    "\n",
    "for i, topic in enumerate(nmf.components_):\n",
    "    top_words = [feature_names[j] for j in topic.argsort()[-10:]]\n",
    "    topic_keywords[f'Topic_{i+1}'] = top_words\n",
    "\n",
    "# Display topic keywords\n",
    "for topic, words in topic_keywords.items():\n",
    "    print(f\"{topic}: {', '.join(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìà Plot: Topic Weight vs IMDb Rating\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4), sharey=True)\n",
    "\n",
    "for i in range(5):\n",
    "    sns.regplot(\n",
    "        data=topics,\n",
    "        x=f'Topic_{i+1}',\n",
    "        y='imdb_score',\n",
    "        ax=axes[i],\n",
    "        scatter_kws={'s': 20, 'alpha': 0.6},\n",
    "        line_kws={'color': 'red'}\n",
    "    )\n",
    "    axes[i].set_title(f\"Topic {i+1} vs IMDb\")\n",
    "    axes[i].set_xlabel(f\"Topic_{i+1}\")\n",
    "    axes[i].set_ylabel(\"IMDb Score\" if i == 0 else \"\")\n",
    "\n",
    "plt.suptitle(\"Topic Weights vs IMDb Rating\", fontsize=16, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
